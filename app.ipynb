{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5effdf0",
   "metadata": {},
   "source": [
    "Idea \n",
    "You might also want to allow users to filter, sort, or search within the data to make it more interactive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "79391f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "streamlit_code = '''\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from xgboost import XGBRegressor\n",
    "import plotly.express as px\n",
    "import holidays\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from io import BytesIO\n",
    "from fpdf import FPDF\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.pdfgen import canvas\n",
    "import logging\n",
    "import datetime\n",
    "import toml\n",
    "import getpass\n",
    "import bcrypt\n",
    "import streamlit_authenticator as stauth\n",
    "\n",
    "# Store user credentials (for simplicity, using plain passwords here)\n",
    "users = {\n",
    "    \"exec_user\": {\n",
    "        \"password\": \"password123\",\n",
    "        \"name\": \"Executive User\"\n",
    "    },\n",
    "    \"finance_user\": {\n",
    "        \"password\": \"securepass456\",\n",
    "        \"name\": \"Finance User\"\n",
    "    },\n",
    "    \"data_user\": {\n",
    "        \"password\": \"datapass789\",\n",
    "        \"name\": \"Data User\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Set up the login form\n",
    "st.title(\"User Login\")\n",
    "\n",
    "# Get username and password input\n",
    "username_input = st.text_input(\"Username\")\n",
    "password_input = st.text_input(\"Password\", type=\"password\")\n",
    "\n",
    "# Initialize session state for login tracking\n",
    "if 'authenticated' not in st.session_state:\n",
    "    st.session_state.authenticated = False\n",
    "\n",
    "# Check if login button is pressed\n",
    "login_button = st.button(\"Login\")\n",
    "\n",
    "if login_button:\n",
    "    # Check if the username exists in the users dictionary\n",
    "    if username_input in users:\n",
    "        # Check if the password is correct\n",
    "        if users[username_input][\"password\"] == password_input:\n",
    "            st.session_state.authenticated = True  # Set authentication state to True\n",
    "            st.success(f\"Welcome {users[username_input]['name']}!\")\n",
    "            st.rerun()\n",
    "        else:\n",
    "            st.error(\"Incorrect password!\")\n",
    "    else:\n",
    "        st.error(\"Invalid credentials\")\n",
    "        \n",
    "    st.title(\"User Login\")\n",
    "\n",
    "# Only show tabs if the user is authenticated\n",
    "if st.session_state.authenticated:\n",
    "    st.title(\"Box Office Revenue Prediction\")\n",
    "\n",
    "    # Define tabs\n",
    "    tab_names = [\n",
    "        \"Upload Data\", \"EDA\", \"Data Cleaning\", \"Feature Engineering\",\n",
    "        \"Model Training\", \"Predictions\", \"Performance\", \"Download Report\"\n",
    "    ]\n",
    "    tabs = st.tabs(tab_names)\n",
    "\n",
    "    with tabs[0]:  # Upload Data\n",
    "        st.header(\"Upload Your Data\")\n",
    "        uploaded_file = st.file_uploader(\"Choose a CSV file\", type=\"csv\")\n",
    "        if uploaded_file is not None:\n",
    "            try:\n",
    "                df = pd.read_csv(uploaded_file)\n",
    "            except Exception as e:\n",
    "                st.error(f\"An error occurred while reading the file: {e}\")\n",
    "                st.session_state.df = df\n",
    "                st.success(\"File uploaded successfully.\")\n",
    "                st.dataframe(df.head())\n",
    "                \n",
    "    # Handle errors for empty files or missing data\n",
    "        if df.empty:\n",
    "            st.error(\"Please upload a valid CSV file.\")\n",
    "        else:\n",
    "            st.success(\"File uploaded successfully.\")\n",
    "\n",
    "    if 'df' in st.session_state:\n",
    "        df = st.session_state.df\n",
    "\n",
    "    # Load the trained model\n",
    "    try:\n",
    "        with open('xgboost_model.pkl', 'rb') as model_file:\n",
    "            model = pickle.load(model_file)\n",
    "    except FileNotFoundError:\n",
    "        st.error(\"Model file not found!\")\n",
    "\n",
    "    st.write(\"Data Preview\")\n",
    "    st.dataframe(df.head())  # Use st.dataframe for better readability\n",
    "    \n",
    "    \n",
    "    with tabs[1]:  # EDA\n",
    "        st.header(\"Exploratory Data Analysis (EDA)\")\n",
    "        st.write(\"Basic Statistics\")\n",
    "        st.write(df.describe())\n",
    "\n",
    "        st.write(\"Correlation Heatmap\")\n",
    "        # Select only numeric columns for correlation heatmap\n",
    "        numeric_df = df.select_dtypes(include=['number'])\n",
    "        corr = numeric_df.corr()\n",
    "        fig = px.imshow(corr, text_auto=True, color_continuous_scale=\"Viridis\")\n",
    "        st.plotly_chart(fig)\n",
    "\n",
    "        # Data Exploration: Additional Features\n",
    "        st.header('Data Exploration')\n",
    "\n",
    "        # Option for users to choose the type of plot for numeric columns\n",
    "        plot_type = st.radio(\"Choose a plot type\", ['Histogram', 'Box Plot'])\n",
    "\n",
    "        # Numeric feature selection (Budget, Revenue, etc.)\n",
    "        numeric_feature = st.selectbox(\"Choose a numeric feature to explore\", \n",
    "                                        ['Production Budget (USD)', 'Domestic Gross (USD)', 'Opening Weekend (USD)'])\n",
    "\n",
    "        # Display Histogram or Box Plot based on user selection\n",
    "        if plot_type == 'Histogram':\n",
    "            st.write(f\"Histogram of {numeric_feature}:\")\n",
    "            fig = px.histogram(df, x=numeric_feature, nbins=50, title=f\"Histogram of {numeric_feature}\")\n",
    "            st.plotly_chart(fig)\n",
    "        else:\n",
    "            st.write(f\"Box Plot of {numeric_feature}:\")\n",
    "            fig = px.box(df, y=numeric_feature, title=f\"Box Plot of {numeric_feature}\")\n",
    "            st.plotly_chart(fig)\n",
    "\n",
    "        # Categorical feature for Bar Chart (e.g., Genre)\n",
    "        st.header(\"Bar Chart for Categorical Features\")\n",
    "\n",
    "        categorical_feature = st.selectbox(\"Choose a categorical feature to explore\", \n",
    "                                    ['Genre', 'Certificates', 'Source'])  # Adjust these based on your data\n",
    "\n",
    "        st.write(f\"Bar chart of {categorical_feature}:\")\n",
    "        bar_fig = px.bar(df, x=categorical_feature, title=f\"Bar Chart of {categorical_feature}\", \n",
    "                    category_orders={categorical_feature: df[categorical_feature].value_counts().index.tolist()})\n",
    "        st.plotly_chart(bar_fig)\n",
    "\n",
    "        # Scatter Plot to visualize relationships between two numeric variables (e.g., Budget vs. Box Office Revenue)\n",
    "        st.header(\"Scatter Plot to Visualize Relationships\")\n",
    "\n",
    "        x_feature = st.selectbox(\"Choose the X-axis feature\", \n",
    "                            ['Production Budget (USD)', 'MetaScore', 'IMDb Rating', 'Opening Weekend (USD)'])\n",
    "\n",
    "        y_feature = st.selectbox(\"Choose the Y-axis feature\", \n",
    "                            ['Domestic Gross (USD)', 'Production Budget (USD)', 'MetaScore', 'IMDb Rating', 'Opening Weekend (USD)'])\n",
    "\n",
    "        st.write(f\"Scatter plot between {x_feature} and {y_feature}:\")\n",
    "        scatter_fig = px.scatter(df, x=x_feature, y=y_feature, title=f\"Scatter Plot: {x_feature} vs {y_feature}\")\n",
    "        st.plotly_chart(scatter_fig)\n",
    "        \n",
    "    with tabs[2]:  # Data Cleaning\n",
    "        st.header(\"Data Cleaning\")\n",
    "        st.write(\"Raw Data Preview:\")\n",
    "        st.dataframe(df.head())\n",
    "\n",
    "        ### Step 1: Remove Invalid Data Points\n",
    "        with st.expander(\"Data Cleaning: Removing Invalid Data Points\"):\n",
    "            df['release_date'] = pd.to_datetime(df['release_date'], errors='coerce')\n",
    "            df['release_year'] = df['release_date'].dt.year\n",
    "\n",
    "            # Explanation for removing 2020 movies with $0 Domestic Gross\n",
    "            st.write(\"Movies released in 2020 with a Domestic Gross of $0 are removed due to potential COVID-19 impacts on box office performance, leading to unreliable revenue data.\")\n",
    "\n",
    "            invalid_movies = df[(df['Domestic Gross (USD)'] == 0) & (df['release_year'] == 2020)]\n",
    "            if not invalid_movies.empty:\n",
    "                st.write(\"Titles being removed:\", invalid_movies['Title'].tolist())\n",
    "\n",
    "            df = df[~df.index.isin(invalid_movies.index)]\n",
    "            df.drop(columns=['release_year'], inplace=True)\n",
    "\n",
    "            st.success(\"Movies with $0 Domestic Gross from 2020 have been successfully removed.\")\n",
    "\n",
    "        ### Step 2: Handle Missing Values\n",
    "        with st.expander(\"Handle Missing Values\"):\n",
    "            numeric_fill = st.radio(\"Numeric columns fill method\", ['Median', 'Mean'])\n",
    "            categorical_fill = st.radio(\"Categorical columns fill method\", ['Mode', 'Custom'])\n",
    "\n",
    "            numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "            if numeric_fill == 'Median':\n",
    "                df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].median())\n",
    "            else:\n",
    "                df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].mean())\n",
    "\n",
    "            categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "            if categorical_fill == 'Mode':\n",
    "                df[categorical_cols] = df[categorical_cols].fillna(df[categorical_cols].mode().iloc[0])\n",
    "            else:\n",
    "                custom_fill_value = st.text_input(\"Enter custom value for missing categorical data\")\n",
    "                if custom_fill_value:\n",
    "                    df[categorical_cols] = df[categorical_cols].fillna(custom_fill_value)\n",
    "\n",
    "        ### Step 3: Feature Engineering\n",
    "        with st.expander(\"Feature Engineering\"):\n",
    "            if st.checkbox(\"Extract Release Year and Month\"):\n",
    "                df['Release Year'] = df['release_date'].dt.year\n",
    "                df['Release Month'] = df['release_date'].dt.month\n",
    "\n",
    "            if st.checkbox(\"Add Holiday Release Feature\"):\n",
    "                us_holidays = holidays.US()\n",
    "                df['Holiday_Release'] = df['release_date'].apply(lambda x: 1 if x in us_holidays else 0)\n",
    "\n",
    "            if st.checkbox(\"Add Week of Year Feature\"):\n",
    "                df['Week_of_Year'] = df['release_date'].dt.isocalendar().week\n",
    "\n",
    "        ### Step 4: Encoding\n",
    "        with st.expander(\"Encoding\"):\n",
    "            if st.checkbox(\"Enable Label Encoding for Genre and Director\"):\n",
    "                label_enc_cols = ['Genre', 'Director']\n",
    "                for col in label_enc_cols:\n",
    "                    encoder = LabelEncoder()\n",
    "                    df[col] = encoder.fit_transform(df[col])\n",
    "\n",
    "            if st.checkbox(\"Enable One-Hot Encoding for 'Certificates', 'Language', and 'Source'\"):\n",
    "                df = pd.get_dummies(df, columns=['Certificates', 'original_language', 'Source'])\n",
    "\n",
    "        ### Step 5: Log Transformation (Optional)\n",
    "        with st.expander(\"Log Transformation (Optional)\"):\n",
    "            apply_log_transform = st.checkbox(\"Apply Log Transform to Skewed Columns\")\n",
    "            if apply_log_transform:\n",
    "                skewed_cols = df.select_dtypes(include=['float64', 'int64']).apply(lambda x: x.skew()).abs()\n",
    "                high_skew = skewed_cols[skewed_cols > 0.75].index\n",
    "                df[high_skew] = df[high_skew].apply(lambda x: np.log1p(x))\n",
    "\n",
    "        st.subheader(\"Final Processed Data\")\n",
    "        st.dataframe(df.head())\n",
    "\n",
    "        # Download processed data\n",
    "        st.subheader(\"Download Processed Data\")\n",
    "        st.download_button(\"Download Processed CSV\", df.to_csv(index=False), \"processed_data.csv\")\n",
    "\n",
    "\n",
    "\n",
    "# Analytical Tools\n",
    "st.title(\"Box Office Revenue Prediction - Analytical Tools\")\n",
    "\n",
    "# Section: Data Overview\n",
    "st.header(\"Data Overview\")\n",
    "if st.checkbox('Show Data Overview'):\n",
    "    st.write(df.head())  # Show top rows of the data\n",
    "    st.write(df.describe())  # Display data statistics\n",
    "    st.write(df.info())  # Display data types and missing values\n",
    "\n",
    "# Ensure the target variable is defined\n",
    "target = 'Domestic Gross (USD)'\n",
    "\n",
    "# Dynamically generate a list of all features (excluding the target)\n",
    "all_features = [col for col in df.columns if col != target]\n",
    "\n",
    "# Set default selected features (choose key features by default)\n",
    "default_features = ['Opening Weekend (USD)']\n",
    "\n",
    "# Ensure the selected default features exist in the dataframe\n",
    "features = [col for col in default_features if col in all_features]\n",
    "\n",
    "# Section: Feature Selection\n",
    "st.header(\"Select Features for Model\")\n",
    "selected_features = st.multiselect(\n",
    "    \"Select the features you want to include in the model:\",\n",
    "    options=all_features,  # Use all features except the target\n",
    "    default=features  # Use only the valid default features\n",
    ")\n",
    "\n",
    "# Ensure at least one feature is selected\n",
    "if not selected_features:\n",
    "    st.warning(\"Please select at least one feature.\")\n",
    "    selected_features = features  # Ensure a default set of features is used\n",
    "\n",
    "# Define X and y after selection\n",
    "X = df[selected_features]\n",
    "y = df[target]\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets (80/20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Section: Correlation Analysis\n",
    "st.header(\"Correlation Analysis\")\n",
    "if st.checkbox('Show Correlation Heatmap'):\n",
    "    corr = df[selected_features + [target]].corr()  # Ensure correlation matches selected features\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    sns.heatmap(corr, annot=True, cmap='seismic', ax=ax)\n",
    "    st.pyplot(fig)\n",
    "\n",
    "            # Section: Model Training & Evaluation\n",
    "    st.title(\"Train and Evaluate Box Office Revenue Model\")\n",
    "\n",
    "    # Select model type (user option)\n",
    "    model_option = st.selectbox(\"Select a Model to Train\", [\"XGBoost\", \"Random Forest\", \"Decision Tree\", \"Linear Regression\"])\n",
    "\n",
    "    # Train and test models based on selection\n",
    "    if model_option == \"XGBoost\":\n",
    "        # Initialize XGBoost Regressor\n",
    "        xgb_model = XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=6)\n",
    "        xgb_model.fit(X_train, y_train)\n",
    "\n",
    "        # Predictions and evaluation\n",
    "        y_pred_xgb = xgb_model.predict(X_test)\n",
    "        mae_xgb = mean_absolute_error(y_test, y_pred_xgb)\n",
    "        r2_xgb = r2_score(y_test, y_pred_xgb)\n",
    "\n",
    "        # Display results\n",
    "        st.subheader(\"Model Evaluation (XGBoost)\")\n",
    "        st.write(f\"Mean Absolute Error (MAE): {mae_xgb:.2f}\")\n",
    "        st.write(f\"R-squared (R²): {r2_xgb:.2f}\")\n",
    "        st.session_state.mae_xgb = mae_xgb\n",
    "        st.session_state.r2_xgb = r2_xgb\n",
    "\n",
    "        # Visualize Actual vs Predicted (XGBoost)\n",
    "        st.subheader(\"Actual vs Predicted (XGBoost)\")\n",
    "        results_df_xgb = pd.DataFrame({\"Actual\": y_test, \"Predicted\": y_pred_xgb})\n",
    "        fig_xgb = px.scatter(results_df_xgb, x=\"Actual\", y=\"Predicted\", title=\"Actual vs Predicted (XGBoost)\")\n",
    "        st.plotly_chart(fig_xgb)\n",
    "\n",
    "    elif model_option == \"Random Forest\":\n",
    "        # Initialize RandomForest Regressor\n",
    "        rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "        rf_model.fit(X_train, y_train)\n",
    "\n",
    "        # Predictions and evaluation\n",
    "        y_pred_rf = rf_model.predict(X_test)\n",
    "        mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
    "        r2_rf = r2_score(y_test, y_pred_rf)\n",
    "\n",
    "        # Display results\n",
    "        st.subheader(\"Model Evaluation (Random Forest)\")\n",
    "        st.write(f\"Mean Absolute Error (MAE): {mae_rf:.2f}\")\n",
    "        st.write(f\"R-squared (R²): {r2_rf:.2f}\")\n",
    "        st.session_state.mae_rf = mae_rf\n",
    "        st.session_state.r2_rf = r2_rf\n",
    "\n",
    "        # Visualize Actual vs Predicted (Random Forest)\n",
    "        st.subheader(\"Actual vs Predicted (Random Forest)\")\n",
    "        results_df_rf = pd.DataFrame({\"Actual\": y_test, \"Predicted\": y_pred_rf})\n",
    "        fig_rf = px.scatter(results_df_rf, x=\"Actual\", y=\"Predicted\", title=\"Actual vs Predicted (Random Forest)\")\n",
    "        st.plotly_chart(fig_rf)\n",
    "\n",
    "        # Store Feature Importances in session_state\n",
    "        st.session_state.importance_rf = rf_model.feature_importances_\n",
    "\n",
    "        # Ensure correct feature names and importance values\n",
    "        if len(selected_features) == len(st.session_state.importance_rf):\n",
    "            importance_df_rf = pd.DataFrame({\n",
    "                'Feature': selected_features,\n",
    "                'Importance': st.session_state.importance_rf\n",
    "            })\n",
    "\n",
    "            # Display Feature Importance\n",
    "            st.subheader(\"Random Forest Feature Importance\")\n",
    "            st.write(importance_df_rf)\n",
    "\n",
    "            fig_rf_imp = px.bar(importance_df_rf, x='Feature', y='Importance', title=\"Feature Importance (Random Forest)\")\n",
    "            st.plotly_chart(fig_rf_imp)\n",
    "        else:\n",
    "            st.error(\"The number of selected features and feature importances do not match!\")\n",
    "\n",
    "    elif model_option == \"Decision Tree\":\n",
    "        # Initialize DecisionTree Regressor\n",
    "        dt_model = DecisionTreeRegressor(random_state=42)\n",
    "        dt_model.fit(X_train, y_train)\n",
    "\n",
    "        # Predictions and evaluation\n",
    "        y_pred_dt = dt_model.predict(X_test)\n",
    "        mae_dt = mean_absolute_error(y_test, y_pred_dt)\n",
    "        r2_dt = r2_score(y_test, y_pred_dt)\n",
    "\n",
    "        # Display results\n",
    "        st.subheader(\"Model Evaluation (Decision Tree)\")\n",
    "        st.write(f\"Mean Absolute Error (MAE): {mae_dt:.2f}\")\n",
    "        st.write(f\"R-squared (R²): {r2_dt:.2f}\")\n",
    "        st.session_state.mae_dt = mae_dt\n",
    "        st.session_state.r2_dt = r2_dt\n",
    "\n",
    "        # Visualize Actual vs Predicted (Decision Tree)\n",
    "        st.subheader(\"Actual vs Predicted (Decision Tree)\")\n",
    "        results_df_dt = pd.DataFrame({\"Actual\": y_test, \"Predicted\": y_pred_dt})\n",
    "        fig_dt = px.scatter(results_df_dt, x=\"Actual\", y=\"Predicted\", title=\"Actual vs Predicted (Decision Tree)\")\n",
    "        st.plotly_chart(fig_dt)\n",
    "\n",
    "    elif model_option == \"Linear Regression\":\n",
    "        # Initialize and train the Linear Regression model\n",
    "        lr_model = LinearRegression()\n",
    "        lr_model.fit(X_train, y_train)\n",
    "\n",
    "        # Make predictions on the test set\n",
    "        y_pred_lr = lr_model.predict(X_test)\n",
    "\n",
    "        # Calculate model performance metrics\n",
    "        mae_lr = mean_absolute_error(y_test, y_pred_lr)\n",
    "        r2_lr = r2_score(y_test, y_pred_lr)\n",
    "\n",
    "        # Store results in session_state\n",
    "        st.session_state.mae_lr = mae_lr\n",
    "        st.session_state.r2_lr = r2_lr\n",
    "\n",
    "        # Display Results\n",
    "        st.subheader(\"Model Evaluation (Linear Regression)\")\n",
    "        st.write(f\"Mean AbsR-squared (R²): {r2_lr:.2f}\")\n",
    "        st.write(f\"R-squared (R²): {r2_lr:.2f}\")\n",
    "\n",
    "        # Visualize Actual vs Predicted\n",
    "        st.subheader(\"Actual vs Predicted (Linear Regression)\")\n",
    "        results_df_lr = pd.DataFrame({\"Actual\": y_test, \"Predicted\": y_pred_lr})\n",
    "        fig_lr = px.scatter(results_df_lr, x=\"Actual\", y=\"Predicted\", title=\"Actual vs Predicted (Linear Regression)\")\n",
    "        st.plotly_chart(fig_lr)\n",
    "\n",
    "        # Section: Model Evaluation Summary\n",
    "    st.header(\"Model Comparison\")\n",
    "\n",
    "    # Ensure session state is properly initialized\n",
    "    if \"results\" not in st.session_state:\n",
    "        st.session_state.results = {}\n",
    "\n",
    "    # Check if features have changed and clear only relevant session state values\n",
    "    if \"prev_features\" not in st.session_state:\n",
    "        st.session_state.prev_features = selected_features\n",
    "    elif st.session_state.prev_features != selected_features:\n",
    "        st.session_state.results.clear()  # Clear only model results, not everything\n",
    "        st.session_state.prev_features = selected_features\n",
    "\n",
    "    # Dictionary to store model results\n",
    "    model_results = {}\n",
    "\n",
    "    # Train selected models dynamically\n",
    "    if model_option == \"Linear Regression\":\n",
    "        lr_model = LinearRegression()\n",
    "        lr_model.fit(X_train, y_train)\n",
    "        y_pred_lr = lr_model.predict(X_test)\n",
    "        model_results[\"Linear Regression\"] = {\n",
    "            \"MAE\": mean_absolute_error(y_test, y_pred_lr),\n",
    "            \"R²\": r2_score(y_test, y_pred_lr),\n",
    "        }\n",
    "\n",
    "    if model_option == \"Decision Tree\":\n",
    "        dt_model = DecisionTreeRegressor()\n",
    "        dt_model.fit(X_train, y_train)\n",
    "        y_pred_dt = dt_model.predict(X_test)\n",
    "        model_results[\"Decision Tree\"] = {\n",
    "            \"MAE\": mean_absolute_error(y_test, y_pred_dt),\n",
    "            \"R²\": r2_score(y_test, y_pred_dt),\n",
    "        }\n",
    "\n",
    "    if model_option == \"Random Forest\":\n",
    "        rf_model = RandomForestRegressor()\n",
    "        rf_model.fit(X_train, y_train)\n",
    "        y_pred_rf = rf_model.predict(X_test)\n",
    "        model_results[\"Random Forest\"] = {\n",
    "            \"MAE\": mean_absolute_error(y_test, y_pred_rf),\n",
    "            \"R²\": r2_score(y_test, y_pred_rf),\n",
    "        }\n",
    "\n",
    "    if model_option == \"XGBoost\":\n",
    "        xgb_model = XGBRegressor()\n",
    "        xgb_model.fit(X_train, y_train)\n",
    "        y_pred_xgb = xgb_model.predict(X_test)\n",
    "        model_results[\"XGBoost\"] = {\n",
    "            \"MAE\": mean_absolute_error(y_test, y_pred_xgb),\n",
    "            \"R²\": r2_score(y_test, y_pred_xgb),\n",
    "        }\n",
    "\n",
    "    # Update session state with the latest results\n",
    "    st.session_state.results.update(model_results)\n",
    "\n",
    "    # Display results dynamically\n",
    "    if st.session_state.results:\n",
    "        eval_df = pd.DataFrame([\n",
    "            {\"Model\": model, \"MAE\": res[\"MAE\"], \"R²\": res[\"R²\"]}\n",
    "            for model, res in st.session_state.results.items()\n",
    "        ])\n",
    "        st.write(eval_df)\n",
    "\n",
    "\n",
    "    if 'lr_model' not in st.session_state:\n",
    "        st.session_state.lr_model = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "    if 'dt_model' not in st.session_state:\n",
    "        st.session_state.dt_model = DecisionTreeRegressor().fit(X_train, y_train)\n",
    "\n",
    "    if 'rf_model' not in st.session_state:\n",
    "        st.session_state.rf_model = RandomForestRegressor().fit(X_train, y_train)\n",
    "\n",
    "    if 'xgb_model' not in st.session_state:\n",
    "        st.session_state.xgb_model = XGBRegressor().fit(X_train, y_train)\n",
    "\n",
    "    # Now create models dictionary\n",
    "    models = {\n",
    "        'Linear Regression': st.session_state.lr_model,\n",
    "        'Decision Tree': st.session_state.dt_model,\n",
    "        'Random Forest': st.session_state.rf_model,\n",
    "        'XGBoost': st.session_state.xgb_model\n",
    "    }\n",
    "\n",
    "    # Remove any models that are None\n",
    "    models = {k: v for k, v in models.items() if v is not None}\n",
    "\n",
    "    def generate_report(selected_models, metrics, X_test, y_test, y_pred_dict):\n",
    "        \"\"\"\n",
    "        Generates a PDF report summarizing model performance.\n",
    "\n",
    "        Parameters:\n",
    "        - selected_models: List of selected model names.\n",
    "        - metrics: List of evaluation metrics (e.g., [\"MAE\", \"R²\"])\n",
    "        - X_test: Features used for testing.\n",
    "        - y_test: Actual target values.\n",
    "        - y_pred_dict: Dictionary containing model predictions.\n",
    "\n",
    "        Returns:\n",
    "        - BytesIO object containing the PDF report.\n",
    "        \"\"\"\n",
    "        buffer = BytesIO()\n",
    "        c = canvas.Canvas(buffer, pagesize=letter)\n",
    "        width, height = letter\n",
    "\n",
    "        c.setFont(\"Helvetica-Bold\", 16)\n",
    "        c.drawString(100, height - 50, \"Model Performance Report\")\n",
    "\n",
    "        y_position = height - 80\n",
    "\n",
    "        c.setFont(\"Helvetica\", 12)\n",
    "        c.drawString(100, y_position, f\"Selected Models: {', '.join(selected_models)}\")\n",
    "        y_position -= 20\n",
    "\n",
    "        # Add evaluation metrics\n",
    "        c.setFont(\"Helvetica-Bold\", 14)\n",
    "        c.drawString(100, y_position, \"Evaluation Metrics\")\n",
    "        y_position -= 20\n",
    "        c.setFont(\"Helvetica\", 12)\n",
    "\n",
    "        for model_name in selected_models:\n",
    "            mae = st.session_state.get(f\"mae_{model_name.lower().replace(' ', '_')}\", \"N/A\")\n",
    "            r2 = st.session_state.get(f\"r2_{model_name.lower().replace(' ', '_')}\", \"N/A\")\n",
    "            c.drawString(100, y_position, f\"{model_name}: MAE = {mae}, R² = {r2}\")\n",
    "            y_position -= 20\n",
    "\n",
    "        # Add spacing\n",
    "        y_position -= 10\n",
    "\n",
    "        # Actual vs. Predicted section\n",
    "        c.setFont(\"Helvetica-Bold\", 14)\n",
    "        c.drawString(100, y_position, \"Actual vs. Predicted\")\n",
    "        y_position -= 20\n",
    "\n",
    "        for model_name in selected_models:\n",
    "            if model_name in y_pred_dict:\n",
    "                c.drawString(100, y_position, f\"Results for {model_name}:\")\n",
    "                y_position -= 20\n",
    "                c.drawString(120, y_position, f\"First 5 Predictions: {y_pred_dict[model_name][:5]}\")\n",
    "                y_position -= 20\n",
    "\n",
    "        # Feature Importance for Tree-Based Models\n",
    "        c.setFont(\"Helvetica-Bold\", 14)\n",
    "        c.drawString(100, y_position, \"Feature Importance (Tree-Based Models)\")\n",
    "        y_position -= 20\n",
    "        for model_name in selected_models:\n",
    "            if model_name in [\"Random Forest\", \"XGBoost\"]:\n",
    "                c.drawString(100, y_position, f\"Feature importance available for {model_name}\")\n",
    "                y_position -= 20\n",
    "\n",
    "        c.save()\n",
    "        buffer.seek(0)\n",
    "        return buffer\n",
    "\n",
    "    st.header(\"Model Evaluation Summary\")\n",
    "\n",
    "    # Allow users to select models for evaluation\n",
    "    selected_models = st.multiselect(\"Select Models for Report\", options=models.keys())\n",
    "\n",
    "    if st.button(\"Generate Report\"):\n",
    "        if not selected_models:\n",
    "            st.warning(\"Please select at least one model to generate the report.\")\n",
    "        else:\n",
    "            eval_data = []\n",
    "            y_pred_dict = {}\n",
    "\n",
    "            for model_name in selected_models:\n",
    "                y_pred = models[model_name].predict(X_test)\n",
    "                y_pred_dict[model_name] = y_pred\n",
    "\n",
    "                if model_name == \"Linear Regression\":\n",
    "                    eval_data.append([\"Linear Regression\", st.session_state.mae_lr, st.session_state.r2_lr])\n",
    "                elif model_name == \"Decision Tree\":\n",
    "                    eval_data.append([\"Decision Tree\", st.session_state.mae_dt, st.session_state.r2_dt])\n",
    "                elif model_name == \"Random Forest\":\n",
    "                    eval_data.append([\"Random Forest\", st.session_state.mae_rf, st.session_state.r2_rf])\n",
    "                elif model_name == \"XGBoost\":\n",
    "                    eval_data.append([\"XGBoost\", st.session_state.mae_xgb, st.session_state.r2_xgb])\n",
    "\n",
    "            eval_df = pd.DataFrame(eval_data, columns=[\"Model\", \"MAE\", \"R²\"])\n",
    "            st.write(eval_df)\n",
    "\n",
    "            # Generate report and store it in session state\n",
    "            report_pdf = generate_report(selected_models, [\"MAE\", \"R²\"], X_test, y_test, y_pred_dict)\n",
    "            st.session_state.report = report_pdf\n",
    "            st.success(\"Report generated! You can now download it.\")\n",
    "\n",
    "    # Button to download report\n",
    "    if \"report\" in st.session_state and st.session_state.report:\n",
    "        st.download_button(\"Download PDF Report\", \n",
    "                           data=st.session_state.report, \n",
    "                           file_name=\"model_performance_report.pdf\", \n",
    "                           mime=\"application/pdf\")\n",
    "    else:\n",
    "        st.warning(\"No report generated yet. Click 'Generate Report' first.\")\n",
    "'''\n",
    "\n",
    "# Write the code to the app.py file\n",
    "with open('app.py', 'w') as f:\n",
    "    f.write(streamlit_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "5b232676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exec_pass = \"$2b$12$gcqcYrf6eeZaOKtKpTj7YeDWFxIED9fY32D7FM7cO7tY8bXIGMHC6\"\n",
      "finance_pass = \"$2b$12$/2Cx59KVwiV7SXCIsmv2beAGT/l5wcBt.QvyL/6zRPlfXmjmzBitW\"\n",
      "data_scientist_pass = \"$2b$12$IY9FU3PwFaHmzM/7zXTPWerYJlx5cj6dcUpjF3y7mJzLiNwbxjGSa\"\n"
     ]
    }
   ],
   "source": [
    "import bcrypt\n",
    "\n",
    "# Define user roles and their passwords\n",
    "passwords = {\n",
    "    \"exec_pass\": \"your_exec_password\",\n",
    "    \"finance_pass\": \"your_finance_password\",\n",
    "    \"data_scientist_pass\": \"your_data_password\"\n",
    "}\n",
    "\n",
    "# Function to hash passwords\n",
    "def hash_password(plain_text_password):\n",
    "    salt = bcrypt.gensalt()\n",
    "    hashed = bcrypt.hashpw(plain_text_password.encode(), salt)\n",
    "    return hashed.decode()  # Convert bytes to string for storage\n",
    "\n",
    "# Hash and store passwords\n",
    "hashed_passwords = {role: hash_password(password) for role, password in passwords.items()}\n",
    "\n",
    "# Print hashed passwords for storing in `secrets.toml`\n",
    "for role, hashed in hashed_passwords.items():\n",
    "    print(f'{role} = \"{hashed}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "67f883a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'credentials': {'usernames': {'exec_user': {'name': 'Executive User', 'password': '$2b$12$0TdMBraFNYlL0d0ifxDH4Oltq0VbIlGTq00hYXh5QIO6wFNIxDtu6'}, 'finance_user': {'name': 'Finance User', 'password': '$2b$12$75iXgqAqH9Xl6UTrsh/9le7xG2j1ioctUo7X5IPwLTZT9HW64RecW'}, 'data_user': {'name': 'Data User', 'password': '$2b$12$1j1U19Sm83PmdYW2/gr8.eywebEKyOL87a8yoeFrJpHad467.fvIS'}}}, 'cookie': {'expiry_days': 1, 'key': 'random_secret_key', 'name': 'app_cookie'}, 'preauthorized': {'emails': ['exec@example.com', 'finance@example.com', 'data@example.com', 'ashleycriswell1210@gmail.com']}}\n"
     ]
    }
   ],
   "source": [
    "import toml\n",
    "\n",
    "with open(\"/Users/ashleycriswell/secrets.toml\", \"r\") as f:\n",
    "    secrets = toml.load(f)\n",
    "\n",
    "print(secrets)  # ✅ See if TOML loads properly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "bb33ddf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "streamlit_code='''\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "import holidays\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from io import BytesIO\n",
    "from fpdf import FPDF\n",
    "import datetime\n",
    "\n",
    "# User authentication (simple for now)\n",
    "users = {\n",
    "    \"exec_user\": \"password123\",\n",
    "    \"finance_user\": \"securepass456\",\n",
    "    \"data_user\": \"datapass789\"\n",
    "}\n",
    "\n",
    "st.title(\"User Login\")\n",
    "\n",
    "username_input = st.text_input(\"Username\")\n",
    "password_input = st.text_input(\"Password\", type=\"password\")\n",
    "login_button = st.button(\"Login\")\n",
    "\n",
    "if 'authenticated' not in st.session_state:\n",
    "    st.session_state.authenticated = False\n",
    "\n",
    "if login_button:\n",
    "    if username_input in users and users[username_input] == password_input:\n",
    "        st.session_state.authenticated = True\n",
    "        st.success(f\"Welcome, {username_input}!\")\n",
    "        st.rerun()\n",
    "    else:\n",
    "        st.error(\"Invalid credentials!\")\n",
    "\n",
    "# Only show tabs if the user is authenticated\n",
    "if st.session_state.authenticated:\n",
    "    st.title(\"Box Office Revenue Prediction\")\n",
    "\n",
    "    # Define tabs\n",
    "    tab_names = [\n",
    "        \"Upload Data\", \"EDA\", \"Data Cleaning\", \"Feature Engineering\",\n",
    "        \"Model Training\", \"Predictions\", \"Performance\", \"Download Report\"\n",
    "    ]\n",
    "    tabs = st.tabs(tab_names)\n",
    "\n",
    "    with tabs[0]:  # Upload Data\n",
    "        st.header(\"Upload Your Data\")\n",
    "        uploaded_file = st.file_uploader(\"Choose a CSV file\", type=\"csv\")\n",
    "        if uploaded_file:\n",
    "            df = pd.read_csv(uploaded_file)\n",
    "            st.session_state.df = df\n",
    "            st.success(\"File uploaded successfully.\")\n",
    "            st.dataframe(df.head())\n",
    "\n",
    "    if 'df' in st.session_state:\n",
    "        df = st.session_state.df\n",
    "\n",
    "        with tabs[1]:  # EDA\n",
    "            st.header(\"Exploratory Data Analysis (EDA)\")\n",
    "            st.write(\"Basic Statistics\")\n",
    "            st.write(df.describe())\n",
    "\n",
    "            st.write(\"Correlation Heatmap\")\n",
    "            numeric_df = df.select_dtypes(include=['number'])\n",
    "            fig = px.imshow(numeric_df.corr(), text_auto=True, color_continuous_scale=\"Viridis\")\n",
    "            st.plotly_chart(fig)\n",
    "\n",
    "        with tabs[2]:  # Data Cleaning\n",
    "            st.header(\"Data Cleaning\")\n",
    "            st.write(\"Handling Missing Values\")\n",
    "            df = df.fillna(df.median())\n",
    "            st.session_state.df = df\n",
    "            st.success(\"Missing values handled.\")\n",
    "\n",
    "        with tabs[3]:  # Feature Engineering\n",
    "            st.header(\"Feature Engineering\")\n",
    "            if st.checkbox(\"Extract Release Year and Month\"):\n",
    "                df['release_date'] = pd.to_datetime(df['release_date'], errors='coerce')\n",
    "                df['Release Year'] = df['release_date'].dt.year\n",
    "                df['Release Month'] = df['release_date'].dt.month\n",
    "                st.session_state.df = df\n",
    "                st.success(\"Features added!\")\n",
    "\n",
    "        with tabs[4]:  # Model Training\n",
    "            st.header(\"Model Training\")\n",
    "            target = \"Domestic Gross (USD)\"\n",
    "            features = [col for col in df.columns if col != target and df[col].dtype in ['int64', 'float64']]\n",
    "            X_train, X_test, y_train, y_test = train_test_split(df[features], df[target], test_size=0.2, random_state=42)\n",
    "            model = RandomForestRegressor()\n",
    "            model.fit(X_train, y_train)\n",
    "            st.session_state.model = model\n",
    "            st.session_state.X_test = X_test\n",
    "            st.session_state.y_test = y_test\n",
    "            st.success(\"Model trained successfully!\")\n",
    "\n",
    "        with tabs[5]:  # Predictions\n",
    "            st.header(\"Predictions\")\n",
    "            if 'model' in st.session_state:\n",
    "                predictions = st.session_state.model.predict(st.session_state.X_test)\n",
    "                st.session_state.predictions = predictions\n",
    "                st.write(\"Predictions:\", predictions[:5])\n",
    "\n",
    "        with tabs[6]:  # Performance Evaluation\n",
    "            st.header(\"Performance Evaluation\")\n",
    "            if 'predictions' in st.session_state:\n",
    "                mae = mean_absolute_error(st.session_state.y_test, st.session_state.predictions)\n",
    "                r2 = r2_score(st.session_state.y_test, st.session_state.predictions)\n",
    "                st.session_state.mae = mae\n",
    "                st.session_state.r2 = r2\n",
    "                st.write(f\"MAE: {mae}\")\n",
    "                st.write(f\"R² Score: {r2}\")\n",
    "\n",
    "        with tabs[7]:  # Download Report\n",
    "            st.header(\"Download Report\")\n",
    "            buffer = BytesIO()\n",
    "            pdf = FPDF()\n",
    "            pdf.add_page()\n",
    "            pdf.set_font(\"Arial\", size=12)\n",
    "            pdf.cell(200, 10, txt=\"Model Performance Report\", ln=True, align='C')\n",
    "            pdf.cell(200, 10, txt=f\"MAE: {st.session_state.mae}\", ln=True)\n",
    "            pdf.cell(200, 10, txt=f\"R² Score: {st.session_state.r2}\", ln=True)\n",
    "            pdf.output(buffer)\n",
    "            buffer.seek(0)\n",
    "            st.download_button(\"Download Report\", buffer, \"report.pdf\", \"application/pdf\")\n",
    "\n",
    "'''\n",
    "\n",
    "# Write the code to the app.py file\n",
    "with open('app.py', 'w') as f:\n",
    "    f.write(streamlit_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "a1f24543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final submission \n",
    "streamlit_code = '''\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from xgboost import XGBRegressor\n",
    "import plotly.express as px\n",
    "import holidays\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from io import BytesIO\n",
    "from fpdf import FPDF\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.pdfgen import canvas\n",
    "import logging\n",
    "import datetime\n",
    "import toml\n",
    "import getpass\n",
    "import bcrypt\n",
    "import streamlit_authenticator as stauth\n",
    "\n",
    "# Store user credentials (for simplicity, using plain passwords here)\n",
    "users = {\n",
    "    \"exec_user\": {\n",
    "        \"password\": \"password123\",\n",
    "        \"name\": \"Executive User\"\n",
    "    },\n",
    "    \"finance_user\": {\n",
    "        \"password\": \"securepass456\",\n",
    "        \"name\": \"Finance User\"\n",
    "    },\n",
    "    \"data_user\": {\n",
    "        \"password\": \"datapass789\",\n",
    "        \"name\": \"Data User\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Set up the login form\n",
    "st.title(\"User Login\")\n",
    "\n",
    "# Get username and password input\n",
    "username_input = st.text_input(\"Username\")\n",
    "password_input = st.text_input(\"Password\", type=\"password\")\n",
    "\n",
    "# Initialize session state for login tracking\n",
    "if 'authenticated' not in st.session_state:\n",
    "    st.session_state.authenticated = False\n",
    "\n",
    "# Check if login button is pressed\n",
    "login_button = st.button(\"Login\")\n",
    "\n",
    "if login_button:\n",
    "    # Check if the username exists in the users dictionary\n",
    "    if username_input in users:\n",
    "        # Check if the password is correct\n",
    "        if users[username_input][\"password\"] == password_input:\n",
    "            st.session_state.authenticated = True  # Set authentication state to True\n",
    "            st.success(f\"Welcome {users[username_input]['name']}!\")\n",
    "            st.rerun()\n",
    "        else:\n",
    "            st.error(\"Incorrect password!\")\n",
    "    else:\n",
    "        st.error(\"Invalid credentials\")\n",
    "        \n",
    "    st.title(\"User Login\")\n",
    "\n",
    "# Only show tabs if the user is authenticated\n",
    "if st.session_state.authenticated:\n",
    "    st.title(\"Box Office Revenue Prediction\")\n",
    "\n",
    "    # Define tabs\n",
    "    tab_names = [\n",
    "        \"Upload Data\", \"EDA\", \"Data Cleaning\", \"Feature Engineering\",\n",
    "        \"Model Training\", \"Predictions\", \"Performance\", \"Download Report\"\n",
    "    ]\n",
    "    tabs = st.tabs(tab_names)\n",
    "\n",
    "    with tabs[0]:  # Upload Data\n",
    "        st.header(\"Upload Your Data\")\n",
    "        uploaded_file = st.file_uploader(\"Choose a CSV file\", type=\"csv\")\n",
    "        if uploaded_file is not None:\n",
    "            try:\n",
    "                df = pd.read_csv(uploaded_file)\n",
    "            except Exception as e:\n",
    "                st.error(f\"An error occurred while reading the file: {e}\")\n",
    "                st.session_state.df = df\n",
    "                st.success(\"File uploaded successfully.\")\n",
    "                st.dataframe(df.head())\n",
    "                \n",
    "        # Handle errors for empty files or missing data\n",
    "        if df.empty:\n",
    "            st.error(\"Please upload a valid CSV file.\")\n",
    "        else:\n",
    "            st.success(\"File uploaded successfully.\")\n",
    "\n",
    "        if 'df' in st.session_state:\n",
    "            df = st.session_state.df\n",
    "\n",
    "    # Load the trained model\n",
    "    try:\n",
    "        with open('xgboost_model.pkl', 'rb') as model_file:\n",
    "            model = pickle.load(model_file)\n",
    "    except FileNotFoundError:\n",
    "        st.error(\"Model file not found!\")\n",
    "\n",
    "    st.write(\"Data Preview\")\n",
    "    st.dataframe(df.head())  # Use st.dataframe for better readability\n",
    "    \n",
    "    \n",
    "    with tabs[1]:  # EDA\n",
    "        st.header(\"Exploratory Data Analysis (EDA)\")\n",
    "        st.write(\"Basic Statistics\")\n",
    "        st.write(df.describe())\n",
    "\n",
    "        st.write(\"Correlation Heatmap\")\n",
    "        # Select only numeric columns for correlation heatmap\n",
    "        numeric_df = df.select_dtypes(include=['number'])\n",
    "        corr = numeric_df.corr()\n",
    "        fig = px.imshow(corr, text_auto=True, color_continuous_scale=\"Viridis\")\n",
    "        st.plotly_chart(fig)\n",
    "\n",
    "        # Data Exploration: Additional Features\n",
    "        st.header('Data Exploration')\n",
    "\n",
    "        # Option for users to choose the type of plot for numeric columns\n",
    "        plot_type = st.radio(\"Choose a plot type\", ['Histogram', 'Box Plot'])\n",
    "\n",
    "        # Numeric feature selection (Budget, Revenue, etc.)\n",
    "        numeric_feature = st.selectbox(\"Choose a numeric feature to explore\", \n",
    "                                        ['Production Budget (USD)', 'Domestic Gross (USD)', 'Opening Weekend (USD)'])\n",
    "\n",
    "        # Display Histogram or Box Plot based on user selection\n",
    "        if plot_type == 'Histogram':\n",
    "            st.write(f\"Histogram of {numeric_feature}:\")\n",
    "            fig = px.histogram(df, x=numeric_feature, nbins=50, title=f\"Histogram of {numeric_feature}\")\n",
    "            st.plotly_chart(fig)\n",
    "        else:\n",
    "            st.write(f\"Box Plot of {numeric_feature}:\")\n",
    "            fig = px.box(df, y=numeric_feature, title=f\"Box Plot of {numeric_feature}\")\n",
    "            st.plotly_chart(fig)\n",
    "\n",
    "        # Categorical feature for Bar Chart (e.g., Genre)\n",
    "        st.header(\"Bar Chart for Categorical Features\")\n",
    "\n",
    "        categorical_feature = st.selectbox(\"Choose a categorical feature to explore\", \n",
    "                                    ['Genre', 'Certificates', 'Source'])  # Adjust these based on your data\n",
    "\n",
    "        st.write(f\"Bar chart of {categorical_feature}:\")\n",
    "        bar_fig = px.bar(df, x=categorical_feature, title=f\"Bar Chart of {categorical_feature}\", \n",
    "                    category_orders={categorical_feature: df[categorical_feature].value_counts().index.tolist()})\n",
    "        st.plotly_chart(bar_fig)\n",
    "\n",
    "        # Scatter Plot to visualize relationships between two numeric variables (e.g., Budget vs. Box Office Revenue)\n",
    "        st.header(\"Scatter Plot to Visualize Relationships\")\n",
    "\n",
    "        x_feature = st.selectbox(\"Choose the X-axis feature\", \n",
    "                            ['Production Budget (USD)', 'MetaScore', 'IMDb Rating', 'Opening Weekend (USD)'])\n",
    "\n",
    "        y_feature = st.selectbox(\"Choose the Y-axis feature\", \n",
    "                            ['Domestic Gross (USD)', 'Production Budget (USD)', 'MetaScore', 'IMDb Rating', 'Opening Weekend (USD)'])\n",
    "\n",
    "        st.write(f\"Scatter plot between {x_feature} and {y_feature}:\")\n",
    "        scatter_fig = px.scatter(df, x=x_feature, y=y_feature, title=f\"Scatter Plot: {x_feature} vs {y_feature}\")\n",
    "        st.plotly_chart(scatter_fig)\n",
    "        \n",
    "    with tabs[2]:  # Data Cleaning\n",
    "        st.header(\"Data Cleaning\")\n",
    "        st.write(\"Raw Data Preview:\")\n",
    "        st.dataframe(df.head())\n",
    "\n",
    "        ### Step 1: Remove Invalid Data Points\n",
    "        with st.expander(\"Data Cleaning: Removing Invalid Data Points\"):\n",
    "            df['release_date'] = pd.to_datetime(df['release_date'], errors='coerce')\n",
    "            df['release_year'] = df['release_date'].dt.year\n",
    "\n",
    "            # Explanation for removing 2020 movies with $0 Domestic Gross\n",
    "            st.write(\"Movies released in 2020 with a Domestic Gross of $0 are removed due to potential COVID-19 impacts on box office performance, leading to unreliable revenue data.\")\n",
    "\n",
    "            invalid_movies = df[(df['Domestic Gross (USD)'] == 0) & (df['release_year'] == 2020)]\n",
    "            if not invalid_movies.empty:\n",
    "                st.write(\"Titles being removed:\", invalid_movies['Title'].tolist())\n",
    "\n",
    "            df = df[~df.index.isin(invalid_movies.index)]\n",
    "            df.drop(columns=['release_year'], inplace=True)\n",
    "\n",
    "            st.success(\"Movies with $0 Domestic Gross from 2020 have been successfully removed.\")\n",
    "\n",
    "        ### Step 2: Handle Missing Values\n",
    "        with st.expander(\"Handle Missing Values\"):\n",
    "            numeric_fill = st.radio(\"Numeric columns fill method\", ['Median', 'Mean'])\n",
    "            categorical_fill = st.radio(\"Categorical columns fill method\", ['Mode', 'Custom'])\n",
    "\n",
    "            numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "            if numeric_fill == 'Median':\n",
    "                df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].median())\n",
    "            else:\n",
    "                df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].mean())\n",
    "\n",
    "            categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "            if categorical_fill == 'Mode':\n",
    "                df[categorical_cols] = df[categorical_cols].fillna(df[categorical_cols].mode().iloc[0])\n",
    "            else:\n",
    "                custom_fill_value = st.text_input(\"Enter custom value for missing categorical data\")\n",
    "                if custom_fill_value:\n",
    "                    df[categorical_cols] = df[categorical_cols].fillna(custom_fill_value)\n",
    "\n",
    "        ### Step 3: Feature Engineering\n",
    "        with st.expander(\"Feature Engineering\"):\n",
    "            if st.checkbox(\"Extract Release Year and Month\"):\n",
    "                df['Release Year'] = df['release_date'].dt.year\n",
    "                df['Release Month'] = df['release_date'].dt.month\n",
    "\n",
    "            if st.checkbox(\"Add Holiday Release Feature\"):\n",
    "                us_holidays = holidays.US()\n",
    "                df['Holiday_Release'] = df['release_date'].apply(lambda x: 1 if x in us_holidays else 0)\n",
    "\n",
    "            if st.checkbox(\"Add Week of Year Feature\"):\n",
    "                df['Week_of_Year'] = df['release_date'].dt.isocalendar().week\n",
    "\n",
    "        ### Step 4: Encoding\n",
    "        with st.expander(\"Encoding\"):\n",
    "            if st.checkbox(\"Enable Label Encoding for Genre and Director\"):\n",
    "                label_enc_cols = ['Genre', 'Director']\n",
    "                for col in label_enc_cols:\n",
    "                    encoder = LabelEncoder()\n",
    "                    df[col] = encoder.fit_transform(df[col])\n",
    "\n",
    "            if st.checkbox(\"Enable One-Hot Encoding for 'Certificates', 'Language', and 'Source'\"):\n",
    "                df = pd.get_dummies(df, columns=['Certificates', 'original_language', 'Source'])\n",
    "\n",
    "        ### Step 5: Log Transformation (Optional)\n",
    "        with st.expander(\"Log Transformation (Optional)\"):\n",
    "            apply_log_transform = st.checkbox(\"Apply Log Transform to Skewed Columns\")\n",
    "            if apply_log_transform:\n",
    "                skewed_cols = df.select_dtypes(include=['float64', 'int64']).apply(lambda x: x.skew()).abs()\n",
    "                high_skew = skewed_cols[skewed_cols > 0.75].index\n",
    "                df[high_skew] = df[high_skew].apply(lambda x: np.log1p(x))\n",
    "\n",
    "        st.subheader(\"Final Processed Data\")\n",
    "        st.dataframe(df.head())\n",
    "\n",
    "        # Download processed data\n",
    "        st.subheader(\"Download Processed Data\")\n",
    "        st.download_button(\"Download Processed CSV\", df.to_csv(index=False), \"processed_data.csv\")      \n",
    "'''\n",
    "\n",
    "# Write the code to the app.py file\n",
    "with open('app.py', 'w') as f:\n",
    "    f.write(streamlit_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "e1779946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final submission \n",
    "streamlit_code = '''\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from xgboost import XGBRegressor\n",
    "import plotly.express as px\n",
    "import holidays\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from io import BytesIO\n",
    "from fpdf import FPDF\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.pdfgen import canvas\n",
    "import logging\n",
    "import datetime\n",
    "import toml\n",
    "import getpass\n",
    "import bcrypt\n",
    "import streamlit_authenticator as stauth\n",
    "import pyotp\n",
    "import time\n",
    "import qrcode\n",
    "from cryptography.fernet import Fernet\n",
    "import sqlite3\n",
    "        \n",
    "# Initialize session state variables if they don't exist\n",
    "if \"authenticated\" not in st.session_state:\n",
    "    st.session_state.authenticated = False\n",
    "if \"last_activity\" not in st.session_state:\n",
    "    st.session_state.last_activity = time.time()\n",
    "if \"username\" not in st.session_state:\n",
    "    st.session_state.username = None\n",
    "if \"mfa_secret\" not in st.session_state:\n",
    "    st.session_state.mfa_secret = None\n",
    "if \"role\" not in st.session_state:\n",
    "    st.session_state.role = None\n",
    "\n",
    "# Load the secret key from a file\n",
    "with open(\"secret.key\", \"rb\") as key_file:\n",
    "    cipher_key = key_file.read()\n",
    "\n",
    "# Create a cipher instance\n",
    "cipher = Fernet(cipher_key)\n",
    "\n",
    "# Database Connection & Fetch User Details\n",
    "def get_user(username):\n",
    "    conn = sqlite3.connect(\"users.db\")\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    cursor.execute(\"SELECT name, password_hash, mfa_secret, role FROM users WHERE username=?\", (username,))\n",
    "    user = cursor.fetchone()\n",
    "    \n",
    "    conn.close()\n",
    "    \n",
    "    if user:\n",
    "        return {\n",
    "            \"name\": user[0],\n",
    "            \"password_hash\": user[1],\n",
    "            \"mfa_secret\": cipher.decrypt(user[2].encode()).decode() if user[2] else None,  # Decrypt MFA secret\n",
    "            \"role\": user[3]\n",
    "        }\n",
    "    return None\n",
    "\n",
    "# Check inactivity timeout (15 minutes)\n",
    "def check_timeout():\n",
    "    if st.session_state.authenticated:\n",
    "        current_time = time.time()\n",
    "        if current_time - st.session_state.last_activity > 900:  # 900 seconds = 15 minutes\n",
    "            st.warning(\"Session timed out due to inactivity. Please log in again.\")\n",
    "            st.session_state.authenticated = False\n",
    "            st.session_state.username = None\n",
    "            st.session_state.role = None\n",
    "            st.rerun()\n",
    "\n",
    "# 🚨 **Ensure NOTHING renders unless the user is authenticated**\n",
    "if not st.session_state.authenticated:\n",
    "\n",
    "    # Render login form\n",
    "    st.title(\"🔒 Secure User Login\")\n",
    "\n",
    "    username_input = st.text_input(\"Username\")\n",
    "    password_input = st.text_input(\"Password\", type=\"password\")\n",
    "    login_button = st.button(\"Login\")\n",
    "\n",
    "    if login_button:\n",
    "        user_data = get_user(username_input)  # Fetch from database\n",
    "\n",
    "        if user_data:\n",
    "            hashed_pw = user_data[\"password_hash\"]\n",
    "\n",
    "            if bcrypt.checkpw(password_input.encode(), hashed_pw.encode(\"utf-8\")):\n",
    "                st.session_state.username = username_input\n",
    "                st.session_state.authenticated = False  # MFA required\n",
    "                st.session_state.role = user_data[\"role\"]\n",
    "\n",
    "                # Generate an MFA secret if the user has never set one up\n",
    "                if user_data[\"mfa_secret\"] is None:\n",
    "                    user_data[\"mfa_secret\"] = pyotp.random_base32()\n",
    "                \n",
    "                st.session_state.mfa_secret = user_data[\"mfa_secret\"]\n",
    "                st.session_state.last_activity = time.time()\n",
    "\n",
    "                st.success(\"✅ Password correct. Please scan the QR code to set up MFA.\")\n",
    "            else:\n",
    "                st.error(\"❌ Incorrect password!\")\n",
    "        else:\n",
    "            st.error(\"❌ Invalid credentials!\")\n",
    "\n",
    "    # MFA Step (only after password is verified)\n",
    "    if st.session_state.username and not st.session_state.authenticated:\n",
    "        st.subheader(\"🔑 Set Up or Enter Your MFA Code\")\n",
    "        totp = pyotp.TOTP(st.session_state.mfa_secret)\n",
    "\n",
    "        # Generate a QR Code for first-time MFA setup\n",
    "        otp_url = totp.provisioning_uri(st.session_state.username, issuer_name=\"Box Office Prediction App\")\n",
    "        qr = qrcode.make(otp_url)\n",
    "        buf = BytesIO()\n",
    "        qr.save(buf, format=\"PNG\")\n",
    "        st.image(buf.getvalue(), caption=\"📷 Scan this QR Code with Google Authenticator\")\n",
    "\n",
    "        mfa_input = st.text_input(\"Enter MFA Code\", type=\"password\")\n",
    "\n",
    "        if st.button(\"Verify MFA\"):\n",
    "            if totp.verify(mfa_input):\n",
    "                st.session_state.authenticated = True\n",
    "                st.session_state.last_activity = time.time()\n",
    "\n",
    "                # Store username in session to fetch user details after rerun\n",
    "                st.session_state.username = username_input  \n",
    "\n",
    "                st.success(\"🎉 MFA Verified! Logging you in...\")\n",
    "                st.rerun()\n",
    "\n",
    "            else:\n",
    "                st.error(\"❌ Invalid MFA Code!\")\n",
    "\n",
    "    st.stop()  # 🚨 **Prevents anything below from rendering unless authenticated**\n",
    "    \n",
    "# 🔓 **User is authenticated, enforce role-based access**\n",
    "check_timeout()  # Ensure inactivity timeout is enforced\n",
    "\n",
    "if st.session_state.authenticated and st.session_state.username:\n",
    "    user_data = get_user(st.session_state.username)  # Re-fetch user data\n",
    "    if user_data:\n",
    "        st.session_state.role = user_data[\"role\"]\n",
    "    else:\n",
    "        st.error(\"⚠️ User not found. Please log in again.\")\n",
    "        st.session_state.authenticated = False\n",
    "        st.session_state.username = None\n",
    "        st.stop()\n",
    "\n",
    "# Ensure role exists before rendering content\n",
    "if not st.session_state.role:\n",
    "    st.error(\"🚫 Unauthorized access. Please contact the admin.\")\n",
    "    st.stop()\n",
    "\n",
    "# Role-Based Access Control\n",
    "if st.session_state.role == \"executive\":\n",
    "    st.subheader(\"📊 Executive Dashboard\")\n",
    "    st.write(\"You can view reports generated by the data science team.\")\n",
    "    # Load and display reports from a database or stored files\n",
    "    \n",
    "elif st.session_state.role == \"finance\":\n",
    "    st.subheader(\"📈 Finance Analyst Workspace\")\n",
    "    st.write(\"You can view reports and run predictive models.\")\n",
    "    # Allow model execution, but restrict raw data access\n",
    "    \n",
    "elif st.session_state.role == \"data_science\":\n",
    "    st.subheader(\"🔬 Data Science Team Dashboard\")\n",
    "    st.write(\"You have full access to reports, model execution, and raw data.\")\n",
    "    # Show full access to all tools, raw data, and model outputs\n",
    "\n",
    "else:\n",
    "    st.error(\"🚫 Unauthorized access. Please contact the admin.\")\n",
    "    st.stop()\n",
    "\n",
    "# Log Out Button (Place this AFTER user authentication check)\n",
    "if st.session_state.authenticated:\n",
    "    if st.sidebar.button(\"🔒 Log Out\"):\n",
    "        st.session_state.logged_out = True  # Set a flag\n",
    "        st.session_state.clear()  # Clears session variables\n",
    "        st.success(\"✅ Logged out successfully. Redirecting...\")\n",
    "        time.sleep(2)\n",
    "        st.rerun()  # Now it will trigger correctly\n",
    "\n",
    "# Main App Content After Authentication\n",
    "st.title(\"🎬 Box Office Revenue Prediction Dashboard\")\n",
    "st.write(\"✅ You are securely logged in.\")\n",
    "\n",
    "# Update last activity time on user interaction\n",
    "if st.button(\"Refresh Session\"):\n",
    "    st.session_state.last_activity = time.time()\n",
    "    st.success(\"🔄 Session refreshed!\")\n",
    "\n",
    "# Only show tabs if the user is authenticated\n",
    "if st.session_state.authenticated:\n",
    "    st.title(\"Box Office Revenue Prediction\")\n",
    "\n",
    "# Define tabs\n",
    "tab_names = [\n",
    "    \"Upload Data\", \"EDA\", \"Data Cleaning\", \"Feature Engineering\",\n",
    "    \"Model Training\", \"Predictions\", \"Performance\", \"Download Report\"\n",
    "]\n",
    "tabs = st.tabs(tab_names)\n",
    "\n",
    "with tabs[0]:  # Upload Data\n",
    "    st.header(\"Upload Your Data\")\n",
    "\n",
    "    # Ensure df exists in session state\n",
    "    if \"df\" not in st.session_state:\n",
    "        st.session_state.df = None\n",
    "\n",
    "# Always show file upload options\n",
    "    uploaded_file = st.file_uploader(\"Upload a CSV file\", type=[\"csv\"])\n",
    "    url_input = st.text_input(\"Or enter a URL to fetch the data\")\n",
    "\n",
    "# Reset data if user removes file\n",
    "    if uploaded_file is None and not url_input:\n",
    "        st.session_state.df = None\n",
    "        st.session_state.cleaned_df = None\n",
    "        st.session_state.processed_df = None  # Clear other stored versions if needed\n",
    "\n",
    "    # Handle File Upload\n",
    "    if uploaded_file is not None:\n",
    "        try:\n",
    "            df = pd.read_csv(uploaded_file)\n",
    "            st.session_state.df = df  # Save to session state\n",
    "            st.success(\"File uploaded successfully.\")\n",
    "            st.dataframe(df.head())\n",
    "        except Exception as e:\n",
    "            st.error(f\"An error occurred while reading the file: {e}\")\n",
    "            st.session_state.df = None  # Ensure df is reset\n",
    "\n",
    "    # Handle URL Input\n",
    "    elif url_input:  \n",
    "        try:\n",
    "            df = pd.read_csv(url_input)\n",
    "            st.session_state.df = df  # Save to session state\n",
    "            st.success(\"Data loaded successfully from URL.\")\n",
    "            st.dataframe(df.head())\n",
    "        except Exception as e:\n",
    "            st.error(f\"An error occurred while reading the URL: {e}\")\n",
    "            st.session_state.df = None\n",
    "\n",
    "    # Retrieve df from session state\n",
    "    if st.session_state.df is not None:\n",
    "        df = st.session_state.df\n",
    "\n",
    "        if df.empty:\n",
    "            st.error(\"The uploaded dataset is empty. Please check your file or URL.\")\n",
    "    else:\n",
    "        st.info(\"No file uploaded or URL entered yet.\")  # ✅ Keep this message but remove global checks\n",
    "\n",
    "    # Load the trained model\n",
    "    try:\n",
    "        with open('xgboost_model.pkl', 'rb') as model_file:\n",
    "            model = pickle.load(model_file)\n",
    "    except FileNotFoundError:\n",
    "        st.error(\"Model file not found!\")\n",
    "\n",
    "with tabs[1]:  # EDA\n",
    "    if st.session_state.role in [\"data_science\", \"finance\"]:\n",
    "        st.header(\"Exploratory Data Analysis (EDA)\")\n",
    "        # (Existing EDA code)\n",
    "\n",
    "        # Ensure df exists before accessing it\n",
    "        if \"df\" not in st.session_state or st.session_state.df is None:\n",
    "            st.warning(\"No data uploaded yet. Please upload a CSV file or URL in the 'Upload Data' tab.\")\n",
    "            st.stop()  # 🚀 This prevents further execution when df is missing\n",
    "\n",
    "        df = st.session_state.df  # Now it's safe to use df\n",
    "\n",
    "        # Display Basic Statistics\n",
    "        st.subheader(\"Basic Statistics\")\n",
    "        st.write(df.describe())\n",
    "\n",
    "        # Correlation Heatmap\n",
    "        st.subheader(\"Correlation Heatmap\")\n",
    "        numeric_df = df.select_dtypes(include=['number'])\n",
    "        if not numeric_df.empty:  # Ensure numeric columns exist\n",
    "            corr = numeric_df.corr()\n",
    "            fig = px.imshow(corr, text_auto=True, color_continuous_scale=\"Viridis\")\n",
    "            st.plotly_chart(fig)\n",
    "        else:\n",
    "            st.warning(\"No numeric columns available for correlation heatmap.\")\n",
    "\n",
    "        # Data Exploration: Additional Features\n",
    "        st.subheader(\"Data Exploration\")\n",
    "\n",
    "        # Option for users to choose the type of plot for numeric columns\n",
    "        plot_type = st.radio(\"Choose a plot type\", ['Histogram', 'Box Plot'])\n",
    "\n",
    "        # Numeric feature selection\n",
    "        numeric_feature = st.selectbox(\"Choose a numeric feature to explore\", \n",
    "                                        ['Production Budget (USD)', 'Domestic Gross (USD)', 'Opening Weekend (USD)'])\n",
    "\n",
    "        # Display Histogram or Box Plot based on user selection\n",
    "        if plot_type == 'Histogram':\n",
    "            fig = px.histogram(df, x=numeric_feature, nbins=50, title=f\"Histogram of {numeric_feature}\")\n",
    "            st.plotly_chart(fig)\n",
    "        else:\n",
    "            fig = px.box(df, y=numeric_feature, title=f\"Box Plot of {numeric_feature}\")\n",
    "            st.plotly_chart(fig)\n",
    "\n",
    "        # Categorical feature for Bar Chart\n",
    "        st.subheader(\"Bar Chart for Categorical Features\")\n",
    "\n",
    "        categorical_feature = st.selectbox(\"Choose a categorical feature to explore\", \n",
    "                                           ['Genre', 'Certificates', 'Source'])\n",
    "\n",
    "        if categorical_feature in df.columns:\n",
    "            bar_fig = px.bar(df, x=categorical_feature, title=f\"Bar Chart of {categorical_feature}\", \n",
    "                            category_orders={categorical_feature: df[categorical_feature].value_counts().index.tolist()})\n",
    "            st.plotly_chart(bar_fig)\n",
    "        else:\n",
    "            st.warning(f\"{categorical_feature} column not found in the dataset.\")\n",
    "\n",
    "        # Scatter Plot to visualize relationships between two numeric variables\n",
    "        st.subheader(\"Scatter Plot to Visualize Relationships\")\n",
    "\n",
    "        x_feature = st.selectbox(\"Choose the X-axis feature\", \n",
    "                                 ['Production Budget (USD)', 'MetaScore', 'IMDb Rating', 'Opening Weekend (USD)'])\n",
    "\n",
    "        y_feature = st.selectbox(\"Choose the Y-axis feature\", \n",
    "                                 ['Domestic Gross (USD)', 'Production Budget (USD)', 'MetaScore', 'IMDb Rating', 'Opening Weekend (USD)'])\n",
    "\n",
    "        scatter_fig = px.scatter(df, x=x_feature, y=y_feature, title=f\"Scatter Plot: {x_feature} vs {y_feature}\")\n",
    "        st.plotly_chart(scatter_fig)\n",
    "    else:\n",
    "        st.warning(\"🚫 You do not have permission to access EDA.\")\n",
    "            \n",
    "with tabs[2]:  # Data Cleaning\n",
    "    if st.session_state.role == \"data_science\":\n",
    "        st.header(\"Data Cleaning\")\n",
    "        st.write(\"You can clean and preprocess data here.\")\n",
    "        \n",
    "        if \"df\" not in st.session_state or st.session_state.df is None or st.session_state.df.empty:\n",
    "            st.warning(\"No data uploaded yet. Please upload a CSV file or URL in the 'Upload Data' tab.\")\n",
    "            st.session_state.cleaned_df = None  # ✅ Reset cleaned_df\n",
    "            st.stop()\n",
    "\n",
    "        # Retrieve or initialize cleaned_df\n",
    "        if \"cleaned_df\" not in st.session_state or st.session_state.cleaned_df is None:\n",
    "            st.session_state.cleaned_df = st.session_state.df.copy()\n",
    "\n",
    "        cleaned_df = st.session_state.cleaned_df  # ✅ Now it's guaranteed to exist\n",
    "\n",
    "        # ✅ Only show the preview if cleaned_df is not empty\n",
    "        if cleaned_df.empty:\n",
    "            st.warning(\"⚠️ No data available for preview.\")\n",
    "        else:\n",
    "            st.subheader(\"Raw Data Preview:\")\n",
    "            st.dataframe(cleaned_df.head())\n",
    "\n",
    "            df = st.session_state.df.copy()  # Copy only when df exists\n",
    "\n",
    "            # Load data into session state if not already present\n",
    "            if \"cleaned_df\" not in st.session_state:\n",
    "                st.session_state.cleaned_df = df.copy()\n",
    "\n",
    "            # Work on a copy of the session state dataframe\n",
    "            cleaned_df = st.session_state.cleaned_df\n",
    "\n",
    "            st.subheader(\"Raw Data Preview:\")\n",
    "            st.dataframe(cleaned_df.head())\n",
    "\n",
    "            ### Step 1: Remove Invalid Data Points\n",
    "            with st.expander(\"Data Cleaning: Removing Invalid Data Points\"):\n",
    "                cleaned_df['release_date'] = pd.to_datetime(cleaned_df['release_date'], errors='coerce')\n",
    "                cleaned_df['release_year'] = cleaned_df['release_date'].dt.year\n",
    "\n",
    "                st.write(\"Movies released in 2020 with a Domestic Gross of $0 are removed due to potential COVID-19 impacts.\")\n",
    "\n",
    "                invalid_movies = cleaned_df[(cleaned_df['Domestic Gross (USD)'] == 0) & (cleaned_df['release_year'] == 2020)]\n",
    "                if not invalid_movies.empty:\n",
    "                    st.write(\"Titles being removed:\", invalid_movies['Title'].tolist())\n",
    "\n",
    "                cleaned_df = cleaned_df[~cleaned_df.index.isin(invalid_movies.index)]\n",
    "                cleaned_df.drop(columns=['release_year'], inplace=True)\n",
    "\n",
    "                st.session_state.cleaned_df = cleaned_df\n",
    "                st.success(\"✅ Movies with $0 Domestic Gross from 2020 have been successfully removed.\")\n",
    "\n",
    "            ### Step 2: Handle Missing Values\n",
    "            with st.expander(\"Handle Missing Values\"):\n",
    "                numeric_fill = st.radio(\"Numeric columns fill method\", ['Median', 'Mean'])\n",
    "                categorical_fill = st.radio(\"Categorical columns fill method\", ['Mode', 'Custom'])\n",
    "\n",
    "                numeric_cols = cleaned_df.select_dtypes(include=['float64', 'int64']).columns\n",
    "                if numeric_fill == 'Median':\n",
    "                    cleaned_df[numeric_cols] = cleaned_df[numeric_cols].fillna(cleaned_df[numeric_cols].median())\n",
    "                else:\n",
    "                    cleaned_df[numeric_cols] = cleaned_df[numeric_cols].fillna(cleaned_df[numeric_cols].mean())\n",
    "\n",
    "                categorical_cols = cleaned_df.select_dtypes(include=['object']).columns\n",
    "                if categorical_fill == 'Mode':\n",
    "                    cleaned_df[categorical_cols] = cleaned_df[categorical_cols].fillna(cleaned_df[categorical_cols].mode().iloc[0])\n",
    "                else:\n",
    "                    custom_fill_value = st.text_input(\"Enter custom value for missing categorical data\")\n",
    "                    if custom_fill_value:\n",
    "                        cleaned_df[categorical_cols] = cleaned_df[categorical_cols].fillna(custom_fill_value)\n",
    "\n",
    "                st.session_state.cleaned_df = cleaned_df\n",
    "\n",
    "            ### Step 3: Feature Engineering\n",
    "            with st.expander(\"Feature Engineering\"):\n",
    "                if st.checkbox(\"Extract Release Year and Month\"):\n",
    "                    cleaned_df['Release Year'] = cleaned_df['release_date'].dt.year\n",
    "                    cleaned_df['Release Month'] = cleaned_df['release_date'].dt.month\n",
    "\n",
    "                if st.checkbox(\"Add Holiday Release Feature\"):\n",
    "                    us_holidays = holidays.US()\n",
    "                    cleaned_df['Holiday_Release'] = cleaned_df['release_date'].apply(lambda x: 1 if x in us_holidays else 0)\n",
    "\n",
    "                if st.checkbox(\"Add Week of Year Feature\"):\n",
    "                    cleaned_df['Week_of_Year'] = cleaned_df['release_date'].dt.isocalendar().week\n",
    "\n",
    "                st.session_state.cleaned_df = cleaned_df\n",
    "\n",
    "            ### Step 4: Encoding\n",
    "            with st.expander(\"Encoding\"):\n",
    "                if st.checkbox(\"Enable Label Encoding for Genre and Director\"):\n",
    "                    label_enc_cols = ['Genre', 'Director']\n",
    "                    for col in label_enc_cols:\n",
    "                        if col in cleaned_df.columns:\n",
    "                            cleaned_df[col] = cleaned_df[col].astype(str)  # Ensure values are strings\n",
    "                            encoder = LabelEncoder()\n",
    "                            cleaned_df[col] = encoder.fit_transform(cleaned_df[col])\n",
    "\n",
    "                if st.checkbox(\"Enable One-Hot Encoding for 'Certificates', 'Language', and 'Source'\"):\n",
    "                    one_hot_cols = ['Certificates', 'original_language', 'Source']\n",
    "                    cleaned_df = pd.get_dummies(cleaned_df, columns=[col for col in one_hot_cols if col in cleaned_df.columns])\n",
    "\n",
    "                st.session_state.cleaned_df = cleaned_df\n",
    "\n",
    "            ### Step 5: Log Transformation (Optional)\n",
    "            with st.expander(\"Log Transformation (Optional)\"):\n",
    "                apply_log_transform = st.checkbox(\"Apply Log Transform to Skewed Columns\")\n",
    "                if apply_log_transform:\n",
    "                    skewed_cols = cleaned_df.select_dtypes(include=['float64', 'int64']).apply(lambda x: x.skew()).abs()\n",
    "                    high_skew = skewed_cols[skewed_cols > 0.75].index\n",
    "                    cleaned_df[high_skew] = cleaned_df[high_skew].fillna(0)  # Fill NaNs before log transform\n",
    "                    cleaned_df[high_skew] = cleaned_df[high_skew].apply(lambda x: np.log1p(x))  # Apply log1p(x)\n",
    "\n",
    "                st.session_state.cleaned_df = cleaned_df\n",
    "\n",
    "            ### Display Processed Data\n",
    "            st.subheader(\"Final Processed Data\")\n",
    "            st.dataframe(cleaned_df.head())\n",
    "\n",
    "            ### Download Processed Data\n",
    "            st.subheader(\"Download Processed Data\")\n",
    "            st.download_button(\"Download Processed CSV\", cleaned_df.to_csv(index=False), \"processed_data.csv\")\n",
    "\n",
    "    else:\n",
    "        st.warning(\"🚫 You do not have permission to access data cleaning.\")\n",
    "'''\n",
    "\n",
    "# Write the code to the app.py file\n",
    "with open('app.py', 'w') as f:\n",
    "    f.write(streamlit_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "fe9c8bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from cryptography.fernet import Fernet\n",
    "import bcrypt\n",
    "\n",
    "# Generate an encryption key (only run once, then store it securely)\n",
    "encryption_key = Fernet.generate_key()\n",
    "cipher = Fernet(encryption_key)\n",
    "\n",
    "# Initialize the database\n",
    "def init_db():\n",
    "    conn = sqlite3.connect(\"users.db\")\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # Create users table\n",
    "    cursor.execute(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS users (\n",
    "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "            username TEXT UNIQUE,\n",
    "            name TEXT,\n",
    "            password_hash TEXT,\n",
    "            mfa_secret TEXT,\n",
    "            role TEXT\n",
    "        )\n",
    "    \"\"\")\n",
    "    \n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "init_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "4eb48413",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyotp\n",
    "def add_user(username, name, password, role):\n",
    "    conn = sqlite3.connect(\"users.db\")\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # Hash password\n",
    "    password_hash = bcrypt.hashpw(password.encode(), bcrypt.gensalt()).decode()\n",
    "    \n",
    "    # Encrypt MFA secret\n",
    "    mfa_secret = pyotp.random_base32()\n",
    "    encrypted_mfa = cipher.encrypt(mfa_secret.encode()).decode()\n",
    "    \n",
    "    # Insert user\n",
    "    cursor.execute(\"INSERT INTO users (username, name, password_hash, mfa_secret, role) VALUES (?, ?, ?, ?, ?)\", \n",
    "                   (username, name, password_hash, encrypted_mfa, role))\n",
    "    \n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "# Example users\n",
    "add_user(\"exec_user\", \"Executive User\", \"password123\", \"executive\")\n",
    "add_user(\"finance_user\", \"Finance User\", \"securepass456\", \"finance\")\n",
    "add_user(\"data_user\", \"Data User\", \"datapass789\", \"data_science\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "dde0ddc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New cipher key generated and saved.\n"
     ]
    }
   ],
   "source": [
    "from cryptography.fernet import Fernet\n",
    "\n",
    "# Generate a new key\n",
    "cipher_key = Fernet.generate_key()\n",
    "\n",
    "# Save it to a file (Do this once and keep the file secure)\n",
    "with open(\"secret.key\", \"wb\") as key_file:\n",
    "    key_file.write(cipher_key)\n",
    "\n",
    "print(\"New cipher key generated and saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "784fd704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cipher Key: b'L87R1MWc-8Ym4muadSRPgyG8yVJekyGOsGK6B-9fCXI='\n"
     ]
    }
   ],
   "source": [
    "with open(\"secret.key\", \"rb\") as key_file:\n",
    "    stored_key = key_file.read()\n",
    "\n",
    "print(\"Cipher Key:\", stored_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "bbd81852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated MFA secret for data_user\n",
      "Updated MFA secret for exec_user\n",
      "Updated MFA secret for finance_user\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pyotp\n",
    "from cryptography.fernet import Fernet\n",
    "\n",
    "# Load correct cipher key\n",
    "with open(\"secret.key\", \"rb\") as key_file:\n",
    "    cipher_key = key_file.read()\n",
    "\n",
    "cipher = Fernet(cipher_key)\n",
    "\n",
    "conn = sqlite3.connect(\"users.db\")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "cursor.execute(\"SELECT username FROM users\")\n",
    "users = cursor.fetchall()\n",
    "\n",
    "for (username,) in users:\n",
    "    new_mfa_secret = pyotp.random_base32()\n",
    "    encrypted_mfa = cipher.encrypt(new_mfa_secret.encode()).decode()\n",
    "    \n",
    "    cursor.execute(\"UPDATE users SET mfa_secret = ? WHERE username = ?\", (encrypted_mfa, username))\n",
    "    print(f\"Updated MFA secret for {username}\")\n",
    "\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5358d63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
